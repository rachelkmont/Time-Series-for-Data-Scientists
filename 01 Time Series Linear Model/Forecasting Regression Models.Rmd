---
title: "Time Series Linear Model Applied"
author: "Rachel Montgomery"
date: "2023-08-28"
output: github_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, cache = TRUE)
library(fpp3)
```

## Assignment 1: Exploring Time Series Data with R

Welcome to the first assignment of our Time Series Analysis class. In
this assignment, we'll be working with real-world time series data to
understand the concepts of linear modeling, regression, and forecasting.
We'll use the R programming language to perform these tasks.

### Section 1: Analyzing Electricity Demand for Australia

Our journey begins with the task of extracting and aggregating time
series data. We're going to work with half-hourly electricity demand
data for Victoria, Australia. Specifically, we'll focus on the demand
data for January 2014 and aggregate it to daily totals, along with
maximum temperature information.

#### Extracting and Aggregating Data

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
jan_vic_elec <- vic_elec %>%
     filter(yearmonth(Time) == yearmonth("2014 Jan")) %>%
     index_by(Date = as_date(Time)) %>%
     summarise(Demand = sum(Demand), Temperature = max(Temperature))
```

#### Plotting and Understanding the Regression Model

Now that we have our data ready, it's time to visualize it. We'll create
a plot to explore the relationship between electricity demand and
temperature. Additionally, we'll find a regression model to explain why
there's a positive relationship between these two variables.

```{r}
# Use tslm function to find the regression model
fit <- jan_vic_elec %>%
  model(tlsm= TSLM (Demand ~ Temperature))

report(fit)
```

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Plot data
jan_vic_elec %>%
  ggplot(aes(x=Temperature, y=Demand)) +
    ylab("Electricity Demand") +
    xlab("Temperature") +
    geom_point() +
    geom_smooth(method="lm", se=FALSE) + #this gives us a line of best fit
#the estimated regression line makes the positive relationship more evident
  theme_minimal()
```

*Why is there a positive relationship?*

I assume the positive relationship indicates the use of air
conditioning. For example, in summer months when it is more hot, people
increase their AC unit usage by having the fan on more constantly and at
lower temperatures, thus increasing the use of electricity.

#### Assessing Model Adequacy

Creating a regression model is just the beginning. To ensure that our
model is adequate, we need to produce a residual plot. This plot will
help us identify any outliers or influential observations that could
affect the validity of our model.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Plot residuals
gg_tsresiduals(fit)
```

*Is the model adequate?*

Yes, the model is adequate. The first plot appears random, with no
patterns. In the autocorrelation plot, no spikes cross the blue lines.
The final plot is somewhat left skewed, which could point to outliers.

#### Forecasting Electricity Demand

Now, let's put our model to use. We'll use it to forecast electricity
demand for two scenarios: one with a maximum temperature of
$15^\circ\text{C}$ and another with a maximum temperature of
$35^\circ\text{C}$. But the question is, can we trust these forecasts?

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Create new future scenarios
future_scenarios <- scenarios(
  'cold' = new_data(jan_vic_elec, 1) %>% #creating one new data 
    mutate(Temperature = 15), #adding temp of 15 to original data
  'hot' = new_data(jan_vic_elec, 1) %>%
    mutate(Temperature = 35))

# Forecast new scenarios
forecast_future<- fit %>%
  forecast(new_data = future_scenarios)

# Plot
autoplot(jan_vic_elec, Demand) +
  autolayer(forecast_future)
```

*Do you believe these forecasts?*

I believe the forecasts for the 35∘C. I doubt it would get to 20∘C in
the summer months.

#### Providing Prediction Intervals

To enhance our forecasts, we'll calculate prediction intervals. This
step adds a layer of uncertainty to our predictions, helping us
understand the potential range of outcomes.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
forecast_future %>%
  hilo() %>%
  select(-.model)
```

#### Analyzing Demand vs. Temperature

Lastly, we'll visualize the relationship between demand and temperature
for all available data. This broader perspective will shed light on the
overall behavior of our model.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
vic_elec %>% # full dataset
  index_by(Date = as_date(Time)) %>% # index by time
  summarise( # summarize demand and temperature
    Demand = sum(Demand),
    Temperature = max(Temperature)
  ) %>%
  ggplot(aes(x = Temperature, y = Demand)) +
  geom_point() +
  theme_minimal()
```

*What does this say about our model?*

The scatterplot indicates that the relationship between electricity
demand and daily max temperature is in fact, not linear. This means that
the assumption of linearity we made previously is incorrect, and that a
linear model won't fit this data.

### Section 2: Analyzing Olympic Running Times

In the second part of our assignment, we'll shift our focus to analyzing
Olympic running times spanning from 1896 to 2016.

#### Visualizing Winning Times Over the Years

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
olympic_running %>%
  ggplot(aes(x = Year, y = Time, colour = Sex)) +
  geom_line() +
  geom_point(size = 1) +
  facet_wrap(~Length, scales = "free_y", nrow = 2) +
  theme_minimal() +
  scale_color_brewer(palette = "Dark2") +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  labs(y = "Running time (seconds)") +
  theme_minimal()

```

*What are the main features of this plot?* For each plot, men are faster
than women, and over time both genders are getting faster. The rate of
decline is less severe from 1980-on.

#### Calculating the Average Rate of Change

A key question we aim to answer in this part is: how have winning times
been changing over the years on average? We'll fit regression lines to
the data to determine the average rate of change per year for each event
category and gender.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Fit time series linear model
fit2 <- olympic_running %>%
  model(tlsm = TSLM(Time ~ trend()))

report(fit2)

olympic_running %>%
  ggplot(aes(x=Time, y=Year)) +
    ylab("Electricity Demand") +
    xlab("Temperature") +
    geom_point() +
  ## adding a line of best fit
    geom_smooth(method="lm", se=FALSE) + 
    theme_minimal()
```

```{r, message = FALSE, warning = FALSE, comment = NA, echo = FALSE, eval = TRUE, results = "asis"}

tidy(fit2) %>% # Name your fit object "fit"
  filter(term == "trend()") %>% # Hint for model to fit: "trend()"
  glue::glue_data("The {Sex}'s {Length} running time has been {ifelse(estimate<0, 'decreasing', 'increasing')} by an average of {abs(round(estimate/4, 3))} seconds each year.<br>")
```

### Assessing Residuals

To further evaluate our models, we'll plot the residuals against the
year. This will help us understand whether our models are suitable for
the data.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
augment(fit2) %>%
  ggplot(aes(x = Year, y = .innov, colour = Sex)) +
  geom_line() +
  geom_point(size = 1) +
  facet_wrap(~Length, scales = "free_y", nrow = 2) +
  theme_minimal() +
  scale_color_brewer(palette = "Dark2") +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  theme_minimal()
```

*What do the residuals indicate about our models?*

Because the plots show different patterns with spikes at different time
spots, the linear trend doesn't seem to fit the data.

### Predicting Winning Times for 2020 Olympics

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}

fit2 %>%
  forecast(h = 1) %>%
  mutate(PI = hilo(Time, 95)) %>%
  select(-.model)
```

*What assumptions have we made in these calculations? We'll discuss the
validity of our predictions and assess their reasonableness.*

In the calculations, we assume that the linear trend of decreasing times
will continue to happen over the years. However, realistically this is
not possible and is unrealistic.

The residual plots showed large residuals for the most recent 20 years,
which indicates that theses winning times aren't linear, and that the
linear model isn't appropriate for further analysis.

### Section 3: Analyzing Souvenirs Sales Data

In the third and final part of our assignment, we'll dive into the world
of souvenirs sales data. This dataset provides monthly sales figures for
a shop located on the wharf at a beach resort town in Queensland,
Australia. The shop sells gifts, souvenirs, and novelties, and its sales
volume varies with the seasonal population of tourists. Notably, the
town experiences a surge in visitors during Christmas and the local
surfing festival held every March since 1988. The shop has also evolved
over time, expanding its premises, product range, and staff.

#### Understanding the Data Patterns

Our journey begins with a time plot of the sales data. By visualizing
the data, we aim to identify patterns and uncover any unusual
fluctuations in the time series.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Plot `souvenirs` data
# Plot `Sales`
souvenirs %>% 
  autoplot(Sales)
```

*Patterns in data*

-   The data exhibits a clear seasonal pattern that repeats
    approximately every year.

-   There's a noticeable spike in sales during December of each year.

-   Starting from 1992, the data shows rapid growth.

#### The Importance of Logarithmic Transformation

Before fitting a regression model, it's essential to explain why we need
to take logarithms of the sales data. This transformation is necessary
to convert the data from an exponential growth model to a linear growth
model. Additionally, taking logarithms stabilizes the pattern and
variance in the data.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Taking logarithm of the data (and plot)
souvenirs %>% autoplot(log(Sales)) #r is great because you can just apply log like that 
```

*After taking the log:*

-   The trend appears more linear.

-   Seasonal variation becomes more constant.

-   The December spike in sales becomes more evident.

#### Fitting a Regression Model

Our final task in this assignment is to fit a regression model to the
logarithms of the sales data. This model will incorporate a linear
trend, seasonal dummies, and a "surfing festival" dummy variable to
account for the impact of the annual surfing festival.

```{r, message = FALSE, warning = FALSE, comment = NA, echo = TRUE, eval = TRUE}
# Data with festival 
souvenirs_festival <- souvenirs %>%
  mutate(festival = month(Month) == 3 & year(Month) != 1987)

# Fit model with trend (log), season, and festival
fit <- souvenirs %>%
  model(reg = TSLM(log(Sales) ~ trend() + season() + festival))

# Plot fitted model with `souvenirs` data
# Plot `Sales`
  souvenirs %>%
  autoplot(Sales, col = "gray") +
  geom_line(data = augment(fit), aes(y = .fitted), col = "blue")
```

This regression model will help us understand the underlying factors
influencing souvenir sales in this coastal town.

### Conclusion

This concludes our exploration of Assignment 1. By working through these
tasks, we've gained valuable insights into time series analysis,
regression modeling, and forecasting. Stay tuned for more assignments as
we dive deeper into the fascinating world of time series data analysis!
