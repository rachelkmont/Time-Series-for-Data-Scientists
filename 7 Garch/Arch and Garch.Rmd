---
title: "Assignment 7"
author: "Rachel Montgomery"
output:
  html_document:
    df_print: paged
---

## ARCH and GARCH Modeling with Mattel Stock Data

Come on Barbie, let's go party!

Financial time series modeling is both a science and an art. It requires a keen understanding of data, market dynamics, and statistical models. Among the various models available, ARCH and GARCH stand out, especially when dealing with financial market data. Today, we're diving deep into these models using Mattel's stock data. Why Mattel? Well, because Barbie and financial modeling both have one thing in common - they never go out of style!

### Introduction to Volatility Modeling

Volatility modeling is at the heart of financial risk management and derivative pricing. The ability to predict future volatility helps traders and risk managers make more informed decisions. So, two models were created for this purpose, ARCH (Autoregressive Conditional Heteroskedasticity) and GARCH (Generalized Autoregressive Conditional Heteroskedasticity.)

*ARCH Models:* Used for financial time series data where volatility clustering is observed. In simple terms, they model the variance of the current error term or volatility as a function of the actual sizes of the previous time periods' error terms.

*GARCH Models:* An extension of ARCH models. They capture a wider range of volatility patterns by considering not just the lagged error terms (like ARCH) but also the lagged variances.

### Data Set-Up

First, let's load in the necessary libraries for our analysis.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, warning = FALSE, message = FALSE, comment = NA, cache = TRUE)
# Load packages
library(vars)
library(urca)
library(rugarch)
library(rmgarch)
library(knitr)
library(kableExtra)
library(fpp2)
library(fpp3)
library(tseries)
library(quantmod)

# Set seed for reproducibility
set.seed(16)
```

Now, let's retrieve the Mattel stock data from Yahoo Finance:

```{r}
## Get Mattel stocks
# Load Mattel stock data from Yahoo Finance using tidyquant's getSymbols function
mattel <- getSymbols(
  "MAT", # Mattel's ticker symbol
  from = "2019-01-01", # Start date
  to = "2022-12-31", # End date
  auto.assign = FALSE # Return the stock data as a data frame
)

```

Let's visualize the stock data:

```{r}
# Visualize Mattel stock data
chart_Series(mattel) 
```

The stock appears to have experienced multiple phases: an initial upward trend, followed by a period of decline, a recovery and another upward trend, and then a slight decline towards the end of the period. Notably, despite challenges like the 2020 pandemic, Mattel displayed resilience, reflecting possibly strong market sentiment or effective company strategies.

This data only goes until the end of 2022, but it would be interesting to see how the Barbie movie (released in July 2023) has influenced their stock.'

### Data Prepping

Before we can proceed with our analysis, we need to convert the stock data into a format that's easier to work with. We'll use the tsibble package:

```{r}
# Convert to data frame
mattel_df <- as.data.frame(mattel)

# Add day as year-month-day
mattel_df$day <- ymd(row.names(mattel_df))

# Convert to time series tibble
mattel_ts <- mattel_df %>%
  as_tsibble(index = day)

```

In financial data, missing values can occur due to non-trading days. We'll fix this:

```{r}
mattel_complete <- mattel_ts %>% fill_gaps()

for(day in 1:nrow(mattel_complete)){
  if(anyNA(mattel_complete[day,])){
    next_day <- day
    while(anyNA(mattel_complete[next_day,])){
      next_day <- next_day + 1
    }
    mattel_complete[day, -ncol(mattel_complete)] <- matrix(
      colMeans(mattel_complete[c(day - 1, next_day), -ncol(mattel_complete)]),
      nrow = 1
    )
  }
}

```

Let's compute the daily returns:

```{r}
# Compute daily returns
mattel_returns <- mattel_complete %>%
  mutate(
    returns = (MAT.Close - lag(MAT.Close)) / lag(MAT.Close)
  ) %>% na.omit()

# Visualize returns
mattel_returns %>%
  ggplot(aes(x = day, y = returns)) +
  geom_col(fill = "#FF92B5") +  # Barbie pink color
  labs(
    title = "Daily Returns for Mattel Stock",
    x = "Date",
    y = "Returns"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))  # Center the plot title

```

At a glance, the returns appear to fluctuate around the zero line, indicating days with both positive and negative returns.

There is some volatility clustering present. We can observe instances of this in the plot where there are clusters of tall bars followed by periods of shorter bars.

#### Stationary Check

Before fitting our ARCH and GARCH models, it's essential to ensure that our data is stationary:

```{r}
mattel_returns %>%
gg_tsdisplay(returns, plot_type = "partial")

```

The residuals do not show significant autocorrelation at various lags, as most of the spikes are within the blue shaded region (confidence bands). This is a good sign, suggesting that the residuals are behaving like white noise, which is what we desire in a well-specified model.

```{r}
mattel_returns %>% features(returns, unitroot_kpss)
```

Given that the p-value is 0.1, at a significance level of 0.05, we fail to reject the null hypothesis, suggesting that the series is stationary around a deterministic trend. Now we can go ahead and start modeling!

### ARCH Model

Setting up and Defining AIC Function:

```{r}
# Define the lags to be considered for the ARCH model
lags <- c(1, 2, 6:8, 11:13)

# Define a function to compute the AIC for a given model fit
aic <- function(fit) {
  LLH <- -sum(fit@fit$log.likelihoods)
  nObs <- fit@model$modeldata$`T`
  nPars <- sum(fit@model$pars[,"Level"] != 0)
  return((-2 * LLH) / nObs + 2 * nPars / nObs)
}

```

Fitting Various ARCH Models with Different Lags:

```{r}
# Fit various ARCH models with different lags and store them in a list
mattel_models <- lapply(lags, function(lag) {
  mattel_arch <- ugarchspec(
    mean.model = list(armaOrder = c(13, 0), include.mean = TRUE),
    variance.model = list(model = "sGARCH", garchOrder = c(lag, 0), include.mean = TRUE),
    distribution.model = "norm"
  )
  return(ugarchfit(mattel_arch, mattel_returns$returns, out.sample = 146))
})

# Name the list of models using the corresponding lags
names(mattel_models) <- lags

# Compute the AIC for each model fit
aic_values <- sapply(mattel_models, aic)
print(aic_values)

```

ARCH(8) is the preferred model based on the AIC values, as it has the smallest value.

#### Model Fit

Final Model Selection and Fitting:

```{r}
# Specify and fit the selected ARCH model (e.g., based on minimum AIC)
mattel_arch <- ugarchspec(
  mean.model = list(armaOrder = c(13, 0), include.mean = TRUE),
  variance.model = list(model = "sGARCH", garchOrder = c(8, 0), include.mean = TRUE),
  distribution.model = "norm"
)

mattel_arch_fit <- ugarchfit(mattel_arch, mattel_returns$returns, out.sample = 146)

# Display the model summary
print(mattel_arch_fit)

# Visualize the fitted model
plot(mattel_arch_fit, which = "all")

```

Let's discuss the model fit.

*Model Specification:*

-   GARCH Model: sGARCH(8,0) - A GARCH model with 8 lags in the autoregressive (AR) process for the variance and no lags in the moving average process, essentially an ARCH(8) model
-   Mean Model: ARFIMA(13,0,0) - The mean of the returns follows an AR process with 13 lags
-   Distribution: The innovations (or errors) are assumed to be normally distributed

*Diagnostic Tests:*

-   Weighted Ljung-Box Test on Standardized Residuals (tests for autocorrelation in the squared residuals): p-values suggest that there might be some remaining ARCH effects, especially given the ssignificant statistic at lag 23

-   Weighted ARCH LM Tests (checks for ARCH effects in the residuals) : p-values indicate that there isn't strong evidence of remaining ARCH effects.

The ARCH(8) model seems to fit the data reasonably well in terms of capturing autocorrelation in the returns.However, there might be some remaining ARCH effects, and the residuals might not be normally distributed. The model might benefit from further refining, possibly by considering different GARCH model variations.

#### Assumption Checks

Checking the normality of the residuals:

```{r}
# 1. Normality of residuals

# Extract residuals from the ARCH/GARCH model
residuals_from_model <- residuals(mattel_arch_fit)


residuals_vector <- as.numeric(residuals_from_model)
shapiro.test(residuals_vector)
qqnorm(residuals_vector)
qqline(residuals_vector)

```

The Shapiro-Wilk test strongly suggests that the residuals are not normally distributed. The Q-Q plot visually confirms a departure from normality, especially at the tails.

So our residuals don't follow a normal distribution - we're not capturing the full dynamics/volatility of Mattel "stonks" with our model.

Checking if the variance of error term follows an AR process:

```{r}
# 2. Absence of ARCH effects in residuals
squared_residuals <- residuals(mattel_arch_fit)^2
acf(squared_residuals, main="ACF of Squared Residuals")

```

The ACF of squared residuals shows significant autocorrelations, especially at the initial lags. This suggests that there's a pattern in the volatility, and that the variance of the error term might be following an autoregressive (AR) process. This is the foundational idea behind ARCH (Autoregressive Conditional Heteroskedasticity) models.

So, based on the ACF plot, it's reasonable to conclude that the variance of the error term shows signs of following an AR process.

Checking the stationarity of residuals:

```{r}
# 3. Stationarity of residuals
adf.test(residuals_from_model)
kpss.test(residuals_from_model)
```

Both the ADF and KPSS tests have p-values less than 0.05, so at that level we can infer that the residuals are stationary.This makes it appropriate for modeling with ARCH/GARCH techniques.

Checking if the coefficients of the variance are positive:

```{r}
# 4. Positive coefficients (directly inspect from the model summary)

# Extracting coefficients from the model fit
coefficients <- coef(mattel_arch_fit)

# Print the coefficients
print(coefficients)

```

The alpha coefficients are all positive, which meets the necessary condition for the GARCH model. This is because the variance must always be positive, and negative coefficients can lead to negative variance predictions, which is not meaningful. So, our model is appropriately specified in terms of positive coefficients for the variance equation.

#### Forecasting

Now, let's forecast.

```{r}
# Create forecast

mattel_fc <- ugarchforecast(
mattel_arch_fit, n.ahead = 1, # forecast next day
n.roll = 146 # usually about 10% of your time series length
)
# Plot
par(mfrow = c(2, 2))
plot(mattel_fc, which = 2)
plot(mattel_fc, which = 3)
plot(mattel_fc, which = 4)
try(plot(mattel_fc, which = 1), silent = TRUE)
par(mfrow = c(1, 1))

```

Let's look at each plot, one at a time.

*Top Left (Rolling forecast vs. actual series with conditional 2-sigma bands):* This plot compares the actual returns with the predicted values from the ARCH model. It indicates a relatively good fit, with the model's forecasts aligning well with the actual returns for the majority of the time, and most of the actual returns lie within the confidence bands.

*Top Right (Forecast unconditional sigma):* This plot displays the model's forecast of the unconditional volatility or sigma over time. The graph is relatively flat with slight fluctuations, which indicates that the long-term volatility forecast of the Mattel stock is fairly stable. This is typical of the unconditional volatility from a GARCH model.

*Bottom Left (Conditional Sigma):* This seems to be a duplicate of the top right plot. It represents the forecast of the unconditional volatility.

Overall, we can say that the ARCH model seems to be well-specified for the Mattel stock data, as it captures both long-term and short-term volatility characteristics.

### GARCH model

There still is volatility and dynamics yet to be captured. Good news for us, there are additional components that can be added to the ARCH model, if we use the GARCH!

GARCH adds a Moving Average component to the errors.

It has the same assumptions as the ARCH model (that we have already met) so we are good to go.

#### Model Fitting

Now, we will specify and fit a GARCH model:

```{r}
mattel_garch <- ugarchspec(
  mean.model = list(armaOrder = c(1, 1), include.mean = TRUE),
  variance.model = list(model = "sGARCH", garchOrder = c(2, 1), include.mean = TRUE),
  distribution.model = "norm"
)

mattel_garch_fit <- ugarchfit(
  mattel_garch, mattel_returns$returns,
  out.sample = 146
)

# Print the GARCH model fit
print(mattel_garch_fit)

```

Let's discuss the model fit.

*Model Specification:*

-   GARCH Model: sGARCH(2,1) - A standard GARCH model with 2 lags of past squared residuals (alpha terms) and 1 lag of past variances (beta term)

-   Mean Model: ARFIMA(1,0,1) - An autoregressive fractionally integrated moving average model with 1 AR term and 1 MA term for the mean equation of the returns

-   Distribution: norm - The residuals are assumed to follow a normal distribution

Let's discuss the fit.

*Diagnostic Tests:*

-   Weighted Ljung-Box Test on Standardized Residuals (tests for autocorrelation in residuals): The high p-values indicate no significant autocorrelation (a good sign) and that the model has captured most of the autoregressive conditional heteroskedasticity in the data.

-   Weighted ARCH LM Tests (checks for remaining ARCH effects) :The high p-values (except at lag 8) suggest that the model has captured most of the autoregressive conditional heteroskedasticity in the data.

#### Forecasting

Now, let's forecast using our GARCH model:

```{r}
garch_fc <- ugarchforecast(
  mattel_garch_fit,
  n.ahead = 1,
  n.roll = 146
)

# Visualize the forecast
par(mfrow = c(2, 2))
plot(garch_fc, which = 2)
plot(garch_fc, which = 3)
plot(garch_fc, which = 4)
try(plot(garch_fc, which = 1), silent = TRUE)

par(mfrow = c(1, 1))

```

Let's look at each plot, one at a time.

*Top Left (Rolling forecast vs. actual series with conditional 2-sigma bands):*

-   This plot shows the actual returns, the predicted (or forecasted) returns, and the 2-sigma confidence bands around those predictions.
-   The model's forecasts align well with the actual returns for the majority of the time, and most of the actual returns lie within the confidence bands.

*Top Right (Forecast unconditional sigma):*

-   This plot displays the model's forecast of the unconditional volatility or sigma over time.

-   The forecasted unconditional volatility seems to oscillate with a periodic pattern.

*Bottom Left (Forecast rolling sigma vs. \|series\|):*

-   This plot compares the model's rolling forecast of volatility (conditional sigma) with the absolute value of the actual returns.
-   The GARCH model seems to be effectively capturing the "volatility clustering" effect, as evident from the close tracking of the blue line with the black line's peaks.

*Bottom Right (Density of Forecasted Returns):*

-   This plot seems to be a duplicate of the top right, as it also represents the forecast of the unconditional volatility.
